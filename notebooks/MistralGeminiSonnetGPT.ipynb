{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l8hfEFnxqR0W",
    "outputId": "2825909b-21a5-4f3c-a125-b21ceecb763a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama_parse\n",
      "  Downloading llama_parse-0.6.4.post1-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting mistralai\n",
      "  Downloading mistralai-1.6.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting llama-cloud-services>=0.6.4 (from llama_parse)\n",
      "  Downloading llama_cloud_services-0.6.9-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting eval-type-backport>=0.2.0 (from mistralai)\n",
      "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: httpx>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from mistralai) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=2.10.3 in /usr/local/lib/python3.11/dist-packages (from mistralai) (2.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from mistralai) (2.8.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mistralai) (0.4.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.28.1->mistralai) (4.9.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.28.1->mistralai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.28.1->mistralai) (1.0.7)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.28.1->mistralai) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.28.1->mistralai) (0.14.0)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.4->llama_parse) (8.1.8)\n",
      "Collecting llama-cloud<0.2.0,>=0.1.17 (from llama-cloud-services>=0.6.4->llama_parse)\n",
      "  Downloading llama_cloud-0.1.17-py3-none-any.whl.metadata (902 bytes)\n",
      "Collecting llama-index-core>=0.11.0 (from llama-cloud-services>=0.6.4->llama_parse)\n",
      "  Downloading llama_index_core-0.12.27-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: platformdirs<5.0.0,>=4.3.7 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.4->llama_parse) (4.3.7)\n",
      "Collecting python-dotenv<2.0.0,>=1.0.1 (from llama-cloud-services>=0.6.4->llama_parse)\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10.3->mistralai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10.3->mistralai) (2.33.0)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10.3->mistralai) (4.13.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->mistralai) (1.17.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (2.0.40)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (3.11.14)\n",
      "Collecting banks<3.0.0,>=2.0.0 (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse)\n",
      "  Downloading banks-2.1.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting dataclasses-json (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (1.2.18)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse)\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (2025.3.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (3.9.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (2.0.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (11.1.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (9.0.0)\n",
      "Collecting tiktoken>=0.3.3 (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse)\n",
      "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (4.67.1)\n",
      "Collecting typing-inspect>=0.8.0 (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (1.17.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.28.1->mistralai) (1.3.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (1.18.3)\n",
      "Collecting griffe (from banks<3.0.0,>=2.0.0->llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse)\n",
      "  Downloading griffe-1.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from banks<3.0.0,>=2.0.0->llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (3.1.6)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (2024.11.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (2.3.0)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (3.1.1)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (24.2)\n",
      "Collecting colorama>=0.4 (from griffe->banks<3.0.0,>=2.0.0->llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->banks<3.0.0,>=2.0.0->llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (3.0.2)\n",
      "Downloading llama_parse-0.6.4.post1-py3-none-any.whl (4.9 kB)\n",
      "Downloading mistralai-1.6.0-py3-none-any.whl (288 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.7/288.7 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
      "Downloading llama_cloud_services-0.6.9-py3-none-any.whl (29 kB)\n",
      "Downloading llama_cloud-0.1.17-py3-none-any.whl (253 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.9/253.9 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llama_index_core-0.12.27-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Downloading banks-2.1.1-py3-none-any.whl (28 kB)\n",
      "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading griffe-1.7.2-py3-none-any.whl (129 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.2/129.2 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Installing collected packages: filetype, dirtyjson, python-dotenv, mypy-extensions, marshmallow, eval-type-backport, colorama, typing-inspect, tiktoken, griffe, mistralai, llama-cloud, dataclasses-json, banks, llama-index-core, llama-cloud-services, llama_parse\n",
      "Successfully installed banks-2.1.1 colorama-0.4.6 dataclasses-json-0.6.7 dirtyjson-1.0.8 eval-type-backport-0.2.2 filetype-1.2.0 griffe-1.7.2 llama-cloud-0.1.17 llama-cloud-services-0.6.9 llama-index-core-0.12.27 llama_parse-0.6.4.post1 marshmallow-3.26.1 mistralai-1.6.0 mypy-extensions-1.0.0 python-dotenv-1.1.0 tiktoken-0.9.0 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install llama_parse mistralai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "gGz8dDWpqnvG"
   },
   "outputs": [],
   "source": [
    "from llama_parse import LlamaParse\n",
    "import nest_asyncio\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5jHrtICvsddr"
   },
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "\n",
    "LLAMA_API_KEY = userdata.get(\"LLAMA_API_KEY\")\n",
    "OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")\n",
    "GEMINI_API_KEY = userdata.get(\"GEMINI_API_KEY\")\n",
    "MISTRAL_API_KEY = userdata.get(\"MISTRAL_API_KEY\")\n",
    "ANTHROPIC_API_KEY = userdata.get(\"ANTHROPIC_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "EagIEFih6jBy"
   },
   "outputs": [],
   "source": [
    "tiff_dir = Path(\"./data/tiff\")\n",
    "pdf_dir = Path(\"./data/pdf\")\n",
    "jpeg_dir = Path(\"./data/jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "ZEPZpqzdPqbJ"
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageSequence\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def tiff_to_pdf(tiff_path: Path) -> None:\n",
    "    pdf_path = pdf_dir / Path(tiff_path.stem).with_suffix(\".pdf\")\n",
    "    print(f\"{tiff_path.name} -> {pdf_path.name}\")\n",
    "\n",
    "    if not os.path.exists(tiff_path):\n",
    "        raise Exception(f\"{tiff_path} does not find.\")\n",
    "    image = Image.open(tiff_path)\n",
    "\n",
    "    images = []\n",
    "    for i, page in enumerate(ImageSequence.Iterator(image)):\n",
    "        page = page.convert(\"RGB\")\n",
    "        images.append(page)\n",
    "    if len(images) == 1:\n",
    "        images[0].save(pdf_path)\n",
    "    else:\n",
    "        images[0].save(pdf_path, save_all=True, append_images=images[1:])\n",
    "    print(\"OK\")\n",
    "\n",
    "\n",
    "def tiff_to_jpeg(tiff_path: Path) -> None:\n",
    "    jpeg_path = jpeg_dir / Path(tiff_path.stem).with_suffix(\".jpeg\")\n",
    "\n",
    "    print(f\"{tiff_path.name} -> {jpeg_path.name}\")\n",
    "\n",
    "    tiff_image = Image.open(tiff_path)\n",
    "    # Convert the image to JPEG format\n",
    "    jpeg_image = tiff_image.convert(\"RGB\")\n",
    "\n",
    "    # Save the JPEG image\n",
    "    jpeg_image.save(str(jpeg_path))\n",
    "    print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FvSj_mq3P-T8",
    "outputId": "d698cdfb-a23c-46e2-de05-c0e0672b960d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 17.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UB04 Matlock.tif -> UB04 Matlock.pdf\n",
      "OK\n",
      "UB04 Matlock.tif -> UB04 Matlock.jpeg\n",
      "OK\n",
      "HCFA.3.tif -> HCFA.pdf\n",
      "OK\n",
      "HCFA.3.tif -> HCFA.jpeg\n",
      "OK\n",
      "HCFA.5.tif -> HCFA.pdf\n",
      "OK\n",
      "HCFA.5.tif -> HCFA.jpeg\n",
      "OK\n",
      "GoodUB04.3_Page_1.tiff -> GoodUB04.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r4it [00:00,  5.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "GoodUB04.3_Page_1.tiff -> GoodUB04.jpeg\n",
      "OK\n",
      "Perfect UB04.tiff -> Perfect UB04.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r6it [00:00,  7.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "Perfect UB04.tiff -> Perfect UB04.jpeg\n",
      "OK\n",
      "Wilson 1500 form.tif -> Wilson 1500 form.pdf\n",
      "OK\n",
      "Wilson 1500 form.tif -> Wilson 1500 form.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r8it [00:01,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "UB04 Morrison.tif -> UB04 Morrison.pdf\n",
      "OK\n",
      "UB04 Morrison.tif -> UB04 Morrison.jpeg\n",
      "OK\n",
      "GoodUB04.3_Page_3.tiff -> GoodUB04.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r9it [00:01,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "GoodUB04.3_Page_3.tiff -> GoodUB04.jpeg\n",
      "OK\n",
      "HCFA.2.tiff -> HCFA.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/PIL/TiffImagePlugin.py:949: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "HCFA.2.tiff -> HCFA.jpeg\n",
      "OK\n",
      "itemized billing1.tif -> itemized billing1.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r11it [00:02,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "itemized billing1.tif -> itemized billing1.jpeg\n",
      "OK\n",
      "HCFA.4.tif -> HCFA.pdf\n",
      "OK\n",
      "HCFA.4.tif -> HCFA.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r12it [00:02,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "GoodUB04.2_Page_3.tiff -> GoodUB04.pdf\n",
      "OK\n",
      "GoodUB04.2_Page_3.tiff -> GoodUB04.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r13it [00:02,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "GoodUB04.2_Page_1.tiff -> GoodUB04.pdf\n",
      "OK\n",
      "GoodUB04.2_Page_1.tiff -> GoodUB04.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r14it [00:02,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "UB04 Forconi 2023.tif -> UB04 Forconi 2023.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r15it [00:03,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "UB04 Forconi 2023.tif -> UB04 Forconi 2023.jpeg\n",
      "OK\n",
      "itemized billing2.tif -> itemized billing2.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r16it [00:03,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "itemized billing2.tif -> itemized billing2.jpeg\n",
      "OK\n",
      "GoodUB04.2_Page_4.tiff -> GoodUB04.pdf\n",
      "OK\n",
      "GoodUB04.2_Page_4.tiff -> GoodUB04.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r17it [00:04,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "GoodUB04.1_Page_1.tiff -> GoodUB04.pdf\n",
      "OK\n",
      "GoodUB04.1_Page_1.tiff -> GoodUB04.jpeg\n",
      "OK\n",
      "GoodUB04.2_Page_2.tiff -> GoodUB04.pdf\n",
      "OK\n",
      "GoodUB04.2_Page_2.tiff -> GoodUB04.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r19it [00:04,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "GoodUB04.3_Page_2.tiff -> GoodUB04.pdf\n",
      "OK\n",
      "GoodUB04.3_Page_2.tiff -> GoodUB04.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r20it [00:04,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "itemized billing3.tif -> itemized billing3.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r21it [00:06,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "itemized billing3.tif -> itemized billing3.jpeg\n",
      "OK\n",
      "HCFA.1.tiff -> HCFA.pdf\n",
      "OK\n",
      "HCFA.1.tiff -> HCFA.jpeg\n",
      "OK\n",
      "UB04 Hill not great quality.tif -> UB04 Hill not great quality.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r23it [00:06,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "UB04 Hill not great quality.tif -> UB04 Hill not great quality.jpeg\n",
      "OK\n",
      "GoodUB04.1_Page_3.tiff -> GoodUB04.pdf\n",
      "OK\n",
      "GoodUB04.1_Page_3.tiff -> GoodUB04.jpeg\n",
      "OK\n",
      "Burris 1500 forms.tiff -> Burris 1500 forms.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [00:06,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "Burris 1500 forms.tiff -> Burris 1500 forms.jpeg\n",
      "OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert tiff to both jpeg and pdf formats\n",
    "for tiff_fp in tqdm(tiff_dir.iterdir()):\n",
    "    if not tiff_fp.is_file():\n",
    "        continue\n",
    "    tiff_to_pdf(tiff_fp)\n",
    "    tiff_to_jpeg(tiff_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "mlqCdTzoqnvO"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from mistralai import Mistral\n",
    "from mistralai import DocumentURLChunk\n",
    "\n",
    "api_key = MISTRAL_API_KEY\n",
    "client = Mistral(api_key=api_key)\n",
    "MISTRAL_MODEL = \"mistral-ocr-latest\"\n",
    "\n",
    "\n",
    "def mistral_ocr(pdf_file):\n",
    "    uploaded_pdf = client.files.upload(\n",
    "        file={\n",
    "            \"file_name\": str(pdf_file),\n",
    "            \"content\": open(pdf_file, \"rb\"),\n",
    "        },\n",
    "        purpose=\"ocr\",\n",
    "    )\n",
    "\n",
    "    signed_url = client.files.get_signed_url(file_id=uploaded_pdf.id)\n",
    "\n",
    "    ocr_response = client.ocr.process(\n",
    "        model=MISTRAL_MODEL,\n",
    "        document=DocumentURLChunk(document_url=signed_url.url),\n",
    "        include_image_base64=True,\n",
    "    )\n",
    "\n",
    "    # Convert response to JSON format\n",
    "    response_dict = json.loads(ocr_response.model_dump_json())\n",
    "    return response_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "4nntg6y6-Jlf"
   },
   "outputs": [],
   "source": [
    "ocr_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "D1NwS0HEqnvP",
    "outputId": "a214f639-d31e-4cae-ecf9-ff2d5fcbdcc9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:26,  2.25s/it]\n"
     ]
    }
   ],
   "source": [
    "mistral_res = {}\n",
    "\n",
    "for pdf_file in tqdm(pdf_dir.iterdir()):\n",
    "    if not pdf_file.is_file():\n",
    "        continue\n",
    "    try:\n",
    "        ocr_result = mistral_ocr(pdf_file)\n",
    "    except Exception as e:\n",
    "        ocr_result = str(e)\n",
    "    mistral_res[str(pdf_file)] = ocr_result\n",
    "\n",
    "\n",
    "for file in mistral_res:\n",
    "    text_content = []\n",
    "    for page in mistral_res[file][\"pages\"]:\n",
    "        text_content.append(page[\"markdown\"])\n",
    "\n",
    "mistral_res = \"\\n\".join(text_content)\n",
    "\n",
    "ocr_results[MISTRAL_MODEL] = mistral_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K5S4GlTm00er",
    "outputId": "bc1b162a-df35-4a81-9e46-0ab6470e9339"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id b52ddb2a-a992-4c70-b977-704af66f7e32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r1it [00:28, 28.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id b0f3eb5f-c24c-4852-a6b5-481bdecc02c5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r2it [00:55, 27.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 9eccfaf6-21dd-4a5b-a53e-d0ee33ea3e81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r3it [01:14, 23.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 29198af8-77d5-4d18-ba7f-45f8edae5245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r4it [01:28, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id eae035b0-f3a4-4489-aa22-368b249d1d12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r5it [01:43, 18.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id c23d73cb-33e1-4e48-95e4-a73e169b67e3\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r6it [02:56, 36.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 4801d698-8e36-49c4-8ab6-ac4f277686c4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r7it [03:23, 33.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 87170992-c218-4a5a-bb85-65ccc9cd21d5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r8it [03:49, 31.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 0256d37e-ef75-47be-8ea0-d04886fbd2f2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r9it [04:16, 29.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 9704c9bb-2479-47ac-9369-f48376044eac\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r10it [05:30, 43.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id ef61a4d7-af15-4491-b89f-f3b4deb65a9d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r11it [05:57, 38.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id e42e787a-a33d-4b93-8e08-d2da03c7e911\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [06:52, 34.36s/it]\n"
     ]
    }
   ],
   "source": [
    "# Gemini 2.0 Flash\n",
    "GEMINI_MODEL = \"gemini-2.0-flash-001\"\n",
    "parser = LlamaParse(\n",
    "    api_key=LLAMA_API_KEY,\n",
    "    result_type=\"markdown\",\n",
    "    verbose=True,\n",
    "    language=\"en\",\n",
    "    take_screenshot=True,\n",
    "    premium_mode=True,\n",
    "    auto_mode_trigger_on_table_in_page=True,\n",
    "    use_vendor_multimodal_model=True,\n",
    "    vendor_multimodal_api_key=GEMINI_API_KEY,\n",
    "    vendor_multimodal_model_name=GEMINI_MODEL,\n",
    ")\n",
    "\n",
    "gemini_res = {}\n",
    "\n",
    "for file in tqdm(pdf_dir.iterdir()):\n",
    "    result = parser.load_data(file)\n",
    "    gemini_res[str(file)] = result[0].get_content()\n",
    "\n",
    "ocr_results[GEMINI_MODEL] = gemini_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "id": "-3FfV5Ad4ViU",
    "outputId": "299e7abd-284f-48cd-c732-c0abcbd914ae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id b39417ec-b4d2-4235-81cb-783676286f79\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r1it [01:30, 90.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 30ccfb77-e1d9-4044-bc48-a80cc0d714df\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r2it [02:31, 73.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 2926f636-1194-4105-8553-ebd7d8990d69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r3it [03:09, 57.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 1679f920-bfef-4bc1-8afe-d99b58570191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r4it [03:52, 51.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 191df752-a77f-40c2-be72-83e561887649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r5it [04:29, 46.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 1fcc2a7d-4d2f-4e5a-a066-b03987785d90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r6it [04:41, 34.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 4eefbf3d-caec-4d70-bb52-3ca11fb47a1f\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r7it [05:35, 40.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 6defda87-8273-46b2-8f6f-8d420d349023\n",
      ".."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r8it [07:33, 65.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id a3121672-334c-4af3-9b70-4f3b462352bd\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r9it [09:09, 75.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id f505ad56-444b-4081-af67-afd461a36fa8\n",
      "..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r9it [12:35, 83.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while parsing the file '<bytes/buffer>': Job ID: f505ad56-444b-4081-af67-afd461a36fa8 failed with status: ERROR, Error code: RATE_LIMIT_EXCEEDED, Error message: Rate limit on vendor model exceeded. Please check your token consumption limits.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-ccf87a80ff62>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0manthropic_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mocr_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mANTHROPIC_MODEL\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manthropic_res\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Sonnet 3.7\n",
    "ANTHROPIC_MODEL = \"anthropic-sonnet-3.7\"\n",
    "parser = LlamaParse(\n",
    "    api_key=LLAMA_API_KEY,\n",
    "    result_type=\"markdown\",\n",
    "    verbose=True,\n",
    "    language=\"en\",\n",
    "    take_screenshot=True,\n",
    "    premium_mode=True,\n",
    "    auto_mode_trigger_on_table_in_page=True,\n",
    "    use_vendor_multimodal_model=True,\n",
    "    vendor_multimodal_api_key=ANTHROPIC_API_KEY,\n",
    "    vendor_multimodal_model_name=ANTHROPIC_MODEL,\n",
    ")\n",
    "\n",
    "anthropic_res = {}\n",
    "\n",
    "for file in tqdm(pdf_dir.iterdir()):\n",
    "    result = parser.load_data(file)\n",
    "    anthropic_res[str(file)] = result[0].get_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "Pe3tq7eqH5Bs"
   },
   "outputs": [],
   "source": [
    "ocr_results[ANTHROPIC_MODEL] = anthropic_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "liWa7ewm5SoO",
    "outputId": "8695f427-334c-49d5-88b5-50c944c68932"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 36313c9c-29a6-488c-903e-ef1bb4a166bf\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r1it [01:09, 69.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 0d8d77e8-2102-4ba6-aa6d-6debb77ef4d1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r2it [01:53, 54.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 287a437b-2746-44b0-b2b4-aba0b9b33863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r3it [01:59, 32.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 06651a20-cfca-463b-aae0-8f838e6b318c\n",
      ".."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r4it [04:25, 77.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 4e37f2a5-bc3a-4ef0-97a7-11633e4e6b81\n",
      ".."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r5it [06:47, 100.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id cad80a29-33b1-445a-9b43-10bd31a37a92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r6it [07:03, 71.99s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 9224ac2b-9c21-49e2-8f86-ba3b5c7b9c36\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r7it [08:17, 72.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id aa203f95-7c9b-4860-b131-0eba65242709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r8it [08:48, 59.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id fd175c6a-ace5-44e6-bbce-28a81065bae9\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r9it [09:46, 58.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id b6fa033e-61d5-4f1a-b28a-b669ab622357\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r10it [11:23, 70.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 460476d2-01ec-483c-9386-e1a327d7ee39\n",
      "..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r11it [14:15, 101.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 695e7e05-d772-4c72-8170-930fc26b9556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [14:42, 73.55s/it]\n"
     ]
    }
   ],
   "source": [
    "# GPT-4o\n",
    "OPENAI_MODEL = \"openai-gpt4o\"\n",
    "\n",
    "parser = LlamaParse(\n",
    "    api_key=LLAMA_API_KEY,\n",
    "    result_type=\"markdown\",\n",
    "    verbose=True,\n",
    "    language=\"en\",\n",
    "    premium_mode=True,\n",
    "    take_screenshot=True,\n",
    "    auto_mode_trigger_on_table_in_page=True,\n",
    "    use_vendor_multimodal_model=True,\n",
    "    vendor_multimodal_api_key=OPENAI_API_KEY,\n",
    "    vendor_multimodal_model_name=OPENAI_MODEL,\n",
    ")\n",
    "\n",
    "openai_res = {}\n",
    "\n",
    "for file in tqdm(pdf_dir.iterdir()):\n",
    "    result = parser.load_data(file)\n",
    "    openai_res[str(file)] = result[0].get_content()\n",
    "\n",
    "ocr_results[OPENAI_MODEL] = openai_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "ZHHW0S5r5UcD"
   },
   "outputs": [],
   "source": [
    "with open(\"/content/results.json\", \"w\") as fp:\n",
    "    json.dump(ocr_results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ndD1h5TeLcBT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}